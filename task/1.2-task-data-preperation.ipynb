{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c4cc8f-c4ca-46c4-8141-b2fcacb99d1d",
   "metadata": {},
   "source": [
    "# Task 1 Part 2: Data preperation\n",
    "In this task we will use function to clean and fix the data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3525fe-43fe-4d0b-8bca-08c02d92a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Validations import *\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module=r'seaborn|pandas')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058c0cb-228c-42a6-a0ff-3e829ba5b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_samples(df, column_name):\n",
    "    \"\"\"\n",
    "    Removes samples from the DataFrame where the specified column has null values, modifying the DataFrame in place.\n",
    "\n",
    "    :param df: pandas DataFrame containing the dataset.\n",
    "    :param column_name: String name of the column to check for null values.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        initial_count = df.shape[0]\n",
    "        df.drop(df[df[column_name].isna()].index, inplace=True)\n",
    "        \n",
    "        num_removed = initial_count - df.shape[0]\n",
    "        if num_removed > 0:\n",
    "            print(f\"Removed {num_removed} samples with null values in '{column_name}'.\")\n",
    "        else:\n",
    "            print(f\"No null values found in '{column_name}'.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "\n",
    "def fix_vlues(df, fill_strategy):\n",
    "    \"\"\"\n",
    "    Fill null values in the DataFrame df based on a given fill strategy, considering sex and age.\n",
    "\n",
    "    :param df: pandas DataFrame containing the dataset.\n",
    "    :param fill_strategy: Dictionary specifying how to fill nulls for each column.\n",
    "    \"\"\"\n",
    "    # Define age groups for segmentation\n",
    "    age_bins = [0, 18, 30, 40, 50, 60, 70, 80, 120]  # Example age groups\n",
    "    df['age_group'] = pd.cut(df['age'], bins=age_bins)\n",
    "\n",
    "    for column, strategy in fill_strategy.items():\n",
    "        # Apply different strategies based on the strategy type\n",
    "        if strategy in [\"mean\", \"median\"]:\n",
    "            for (sex, age_group), group_df in df.groupby(['sex', 'age_group'], observed=True):\n",
    "                if strategy == \"mean\":\n",
    "                    value_to_fill = group_df[column].mean()\n",
    "                elif strategy == \"median\":\n",
    "                    value_to_fill = group_df[column].median()\n",
    "                \n",
    "                # Fill null values for the specific sex and age group\n",
    "                df.loc[(df['sex'] == sex) & (df['age_group'] == age_group) & (df[column].isnull()), column] = value_to_fill\n",
    "\n",
    "        elif strategy == \"zero\":\n",
    "            df[column].fillna(0, inplace=True)\n",
    "    \n",
    "    # Clean up by removing the temporary 'age_group' column\n",
    "    df.drop('age_group', axis=1, inplace=True)\n",
    "\n",
    "def remove_negative_samples(df, column_name):\n",
    "    \"\"\"\n",
    "    Removes samples from the DataFrame where the specified column has negative values, modifying the DataFrame in place.\n",
    "\n",
    "    :param df: pandas DataFrame containing the dataset.\n",
    "    :param column_name: String name of the column to check for negative values.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        initial_count = df.shape[0]\n",
    "        # Remove rows with negative values in the specified column in place\n",
    "        df.drop(df[df[column_name] < 0].index, inplace=True)\n",
    "        \n",
    "        num_removed = initial_count - df.shape[0]\n",
    "        if num_removed > 0:\n",
    "            print(f\"Removed {num_removed} samples with negative values in '{column_name}'.\")\n",
    "        else:\n",
    "            print(f\"No negative values found in '{column_name}'.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "\n",
    "def remove_samples_below_threshold(df, column_name, threshold):\n",
    "    \"\"\"\n",
    "    Removes samples from the DataFrame where the value in the specified column is lower than the given threshold,\n",
    "    modifying the DataFrame in place.\n",
    "\n",
    "    :param df: pandas DataFrame containing the dataset.\n",
    "    :param column_name: String name of the column to check values in.\n",
    "    :param threshold: Numeric value representing the threshold below which samples will be removed.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        initial_count = df.shape[0]\n",
    "        # Remove rows with values below the threshold in the specified column in place\n",
    "        df.drop(df[df[column_name] < threshold].index, inplace=True)\n",
    "        \n",
    "        num_removed = initial_count - df.shape[0]\n",
    "        if num_removed > 0:\n",
    "            print(f\"Removed {num_removed} samples with values in '{column_name}' below {threshold}.\")\n",
    "        else:\n",
    "            print(f\"No samples with values in '{column_name}' below {threshold} found.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "\n",
    "def remove_outliers(df, column, method=\"IQR\"):\n",
    "    \"\"\"\n",
    "    Remove or cap outliers in a specified column based on the IQR method or a defined cap.\n",
    "\n",
    "    :param df: pandas DataFrame containing the dataset.\n",
    "    :param column: Column to check for outliers.\n",
    "    :param method: Method to use for outlier detection ('IQR' for Interquartile Range).\n",
    "    :param cap: Optional tuple (min, max) to cap values.\n",
    "    \"\"\"\n",
    "    if method == \"IQR\":\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df[column] = df[column].clip(lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "def remove_feature(df, column_name):\n",
    "    \"\"\"\n",
    "    Remove a specified feature (column) from the DataFrame if it exists.\n",
    "\n",
    "    :param df: pandas DataFrame from which to remove the column.\n",
    "    :param column_name: String name of the column to be removed.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        df.drop(column_name, axis=1, inplace=True)\n",
    "        print(f\"Column '{column_name}' has been removed.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "\n",
    "def convert_feature_to_numeric(df, column_name):\n",
    "    \"\"\"\n",
    "    Convert a feature with boolean values or two categorical options into 0 and 1.\n",
    "\n",
    "    :param df: pandas DataFrame containing the dataset.\n",
    "    :param column_name: String name of the column to convert.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        # Check if column is boolean, or has exactly two unique categories/values\n",
    "        if df[column_name].dtype == 'bool':\n",
    "            # Directly map boolean to 0 and 1\n",
    "            df[column_name] = df[column_name].astype(int)\n",
    "            print(f\"Column '{column_name}' has been converted to numeric values.\")\n",
    "        elif df[column_name].nunique() == 2:\n",
    "            # Convert two unique values/categories to 0 and 1 if not boolean but binary\n",
    "            mapping = {v: i for i, v in enumerate(df[column_name].unique())}\n",
    "            df[column_name] = df[column_name].map(mapping)\n",
    "            print(f\"Column '{column_name}' has been converted to numeric values using mapping: {mapping}\")\n",
    "        else:\n",
    "            print(f\"Column '{column_name}' is not of a type or does not have a value count that allows for direct conversion.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d238b1-4afa-4146-95ea-3aa7653f7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/salary-dataset.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a0280-4a00-49a8-8760-f80a5741c206",
   "metadata": {},
   "source": [
    "## Remove bad samples\n",
    "Bad samples are usually the ones that are missing data in the \"label\" that we want to predict, making them useless for us.\n",
    "\n",
    "There should be one feature that is what we wish to predict.</br>\n",
    "Your task:</br>\n",
    "Fill in the column name and run the functions.</br>el training.</p>\r\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <p>\n",
    "         What we are trying to do? what do we wish to predict?\n",
    "     </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <p>\n",
    "        remove_bad_samples(df,'income')\n",
    "     </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0037d-bef8-4d46-af49-f4416a3bac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e73a01-7be3-42c1-8d5b-08d74db87439",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_bad_samples(df,'---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d9bd5-5134-45cf-a468-6063ab5c8171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cf653-ae96-46a8-832b-1a55bb880012",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "Outliers are data points that significantly differ from other observations. They can skew the results of data analysis and lead to misleading conclusions because they may indicate variability in the data, experimental errors, or a novelty not accounted for by the model. In machine learning, they can affect the training process, resulting in a model that doesn’t perform well with the typical data it encounters.\n",
    "\n",
    "There are many ways to handle outliers, In this case, we will remove low/negative values and IQR. </br>\n",
    "The IQR method uses the middle 50% range of data to create a “normal zone” and flags any points outside this zone as outliers. It's like drawing lines in the sand; anything outside those lines is considered unusual.</br>\n",
    "\n",
    "There should be two features that have outlier data.</br>\n",
    "Your task:</br>\n",
    "Fill in the columns and run the functions.</br>\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <p>\n",
    "         One of the features shouldn't have negative values, and the other shouldn't have such low values.\n",
    "     </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <p>\n",
    "        remove_negative_samples(df, 'income')</br>\n",
    "        remove_samples_below_threshold(df,'weight',20)</br>\n",
    "        remove_outliers(df, 'income', method=\"IQR\")</br>\n",
    "        remove_outliers(df, 'weight', method=\"IQR\")</br>\n",
    "     </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d91c56-fa88-4ae9-82cc-f824ec90886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(df, '---')\n",
    "plot_feature_distribution(df, '---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c2356-e0c3-4ab9-86ca-3ae96c86aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_negative_samples(df, '---')\n",
    "remove_samples_below_threshold(df,'---',20)\n",
    "remove_outliers(df, '---', method=\"IQR\")\n",
    "remove_outliers(df, '---', method=\"IQR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e81cd3-fa43-4d8a-9780-c791fc6a61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(df, '---')\n",
    "plot_feature_distribution(df, '---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bee5c6-3191-4ca6-a109-1e1cf708c9a5",
   "metadata": {},
   "source": [
    "## Fix features with null\n",
    "\n",
    "Null values in data can be problematic because they represent missing, unknown, or unrecorded information, which can lead to inaccurate analyses, biased results, and ultimately poor decision-making. They can also disrupt the performance of many machine learning algorithms, which require complete data sets to function correctly. </br></br>\n",
    "Should be 4 features with null that need to be fixed - to fix we need to find the features and pick for each one of them how to handle and missing data.</br>\n",
    "There are many ways to handle null values, in our case, because we have null value on numerical fileds, we will use math to fill in.\n",
    "\n",
    "The strategies:\n",
    "1. mean - put in the mean value of the feature based on sex and age.\n",
    "2. meadian - put in the median value of the feature based on sex and age.\n",
    "3. zero - put zero as the value.</br>\n",
    "\n",
    "Your task:</br>\n",
    "Add to the \"fill_strategy\" map the name of the features with null values as key, and the strategy as value.</br>\n",
    "fill_strategy = {'feature_name':'strategy',...} </br>\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <p>\n",
    "        Should think of what is more reasanable and logical to put based on the feature!</br>\n",
    "        You can't have 1.2 kids right?\n",
    "     </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <p>\n",
    "        fill_strategy = {'income': 'mean', \"childrens\":'median', \"weight\":'mean', \"height\":'mean'}\n",
    "     </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f8e76-8459-443d-9ea4-bf71f26516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d8acf-d499-4278-920a-07b034d50452",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_strategy = {'---':'median', '---':'mean', '---':'mean'}\n",
    "fix_vlues(df, fill_strategy)\n",
    "check_nulls_and_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81f7af-b4a4-4763-bded-b40242673180",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "Removing features, also known as feature selection, can improve a model's performance by eliminating irrelevant or redundant data, reducing overfitting, and making the model simpler and faster to run.\n",
    "\n",
    "There should be 3 features that are irrelevant to our goal.\n",
    "Your task:</br>\n",
    "Fill in the columns and run the functions.</br>\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <p>\n",
    "         They are features that will not help us with the task, think if someone asked you \"Guess my salary!\" what information is useless from the feature?\n",
    "     </p>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <p>\n",
    "        remove_feature(df, 'name')</br>\n",
    "        remove_feature(df, 'last_name')</br>\n",
    "        remove_feature(df, 'id')</br>\n",
    "     </p>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cc3ce-c715-4185-b9e9-a17fc16a245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_feature(df, '---')\n",
    "remove_feature(df, '---')\n",
    "remove_feature(df, '---')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9083e29-2aa3-41e2-b0d1-7d55bfa626f4",
   "metadata": {},
   "source": [
    "## Features to numbers\n",
    "Changing booleans (True/False values) to numeric values (like 0 and 1) is important, why?</br>\n",
    "Some ML algorithms can only handle numerical values. Transforming booleans into numbers ensures that these algorithms can process the data without errors.\n",
    "\n",
    "There should be 1 boolean feature.\n",
    "<details>\n",
    "    <summary>Solution</summary>\n",
    "    <p>\n",
    "        convert_feature_to_numeric(df, 'married')\n",
    "     </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f4650-9f09-4076-80cb-2c9f61f356f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_feature_to_numeric(df, '---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44a115-f26f-470f-a32b-9ed700576488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
